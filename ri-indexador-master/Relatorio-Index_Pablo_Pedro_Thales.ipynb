{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a51aef20",
   "metadata": {},
   "source": [
    "# Relatório TP2 Indexador\n",
    "\n",
    "##### Disciplina: Tópicos Especiais em Computação e Algoritmos: Recuperação de Informação\n",
    "\n",
    "##### Professor: Daniel Hasan Dalip\n",
    "    \n",
    "##### Alunos: Pablo Vasconcelos da Cruz, Pedro Henrique Maia Duarte e Thales Henrique Bastos Neves\n",
    "\n",
    "Obs: Foi retirado os índices do occur_idx_file_0 até o occur_idx_file_16, o wiki_idx, e também foi retirado o banco de dados ri-tp-wiki-data-master, pois eles ocupavam bastante espaço para serem compilados e enviados para correção."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b76019cc",
   "metadata": {},
   "source": [
    "### Discussão sobre a decisão de implementação adotada:\n",
    "   Quais foram os principais desafios e soluções?\n",
    "   \n",
    "    - Os principais desafios foram a implementação da estrutura de forma que tivemos bastante divergência em como seria feito algumas das atividades propostas, outro desafio foi na hora de implementar os termos em memoria secundária ou primária em que tivemos que discutir bastante em como deveria ser implementado de forma clara.\n",
    "\n",
    "    - Entender o funcionamento das bibliotecas externas para serem utilizadas na prática, entendimento de como os teste funcionavam para conseguirmos debugar quando ocorria algum problema e como seria possivel perceber a diferença entre as duas memo\n",
    "\n",
    "    - Na análise dos resultados. O teste do desafio 16 não estava de acordo com os testes do professor. O resultado do nosso trabalho deu 1250 para a palavra 'horizonte', porém o resultado do teste deveria ser 1251. Não foi possível encontrar a causa dessa diferença."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "324737c3",
   "metadata": {},
   "source": [
    "### Qual é a vantagem/desvantagem das suas soluções sob as outras alternativas (por exemplo, uso do índice em memória principal x ocorrência de termos em memória secundária)?\n",
    "\n",
    "- Fazer a indexação totalmente pela memória principal poderia facilitar o acesso aos dados, mas pode exigir muito do hardware do computador e fica difícil prever o tamanho do espaço ocupado, pois não se sabe quantas palavras em documentos diferentes existem.\n",
    "\n",
    "- Vantagens: Menor quantidade de memória principal gasta. Pode ser executado em máquinas com pouca memória principal. Maior quantidade de índices poderão ser armazenados. Se houver falha na execução é possível recuperar parte do progresso.\n",
    "\n",
    "- Desvantagens: Maior operações de no disco rígido o que resulta em maior tempo gasto na indexação e consequentemente em maior tempo de busca no índice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f98578a",
   "metadata": {},
   "source": [
    "### O que você melhoraria  no seu código para diminuir o consumo de memoria ou deixá-lo mais eficiente?\n",
    "\n",
    "Para diminuir o consumo de memória e deixá-lo mais eficiente poderia ser utilizado uma lista maior de stopwords, afim de diminuir a quantidade de termos irrelevantes a serem indexados, além disso poderiamos utilizar melhor de forma eficiente a indexação na memória secundária, pois ainda leva muito tempo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "148b79a9",
   "metadata": {},
   "source": [
    "### Quais são as bibliotecas externas utilizadas? Explique o funcionamento da técnica de stemming adotada.\n",
    "\n",
    "As bibliotecas externas: nltk (SnowballStemmer e word_tokenize), bs4 (BeautifulSoup), pickle (dump e load), gc, os, datetime, math, tracemalloc, unittest\n",
    "\n",
    "Para cada página coletada, foi extraído seu conteúdo (removendo as tags HTML). Depois o texto foi transformado para LOWERCASE.\n",
    "\n",
    "Depois, fizemos o word_tokenize, gerando um vetor para cada token. Então, para cada token verificamos se ele não possui acento, e se não é uma stopword. Por último foi feito o stemming, em que foi removido o radical de cada termo\n",
    "\n",
    "O Snowball Stemmer é uma ferramenta de NLP que emprega um conjunto de regras para derivar a raiz de uma palavra, ou seja, sua forma fundamental. O propósito do Snowball Stemmer é unificar palavras distintas que possuem a mesma raiz em uma forma comum.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59f15d1b",
   "metadata": {},
   "source": [
    "### Qual foi a estrutura do índice utilizado? \n",
    "A estrutura utilizada do índice foi a seguinte:\n",
    "\n",
    "O índice é representado pela classe TermOccurence que salva o documento doc_id, o termo term_id e a frequência do termo que é  term_freq.\n",
    "\n",
    "class TermOccurrence:\n",
    "    def __init__(self, doc_id: int, term_id: int, term_freq: int):\n",
    "        self.doc_id = doc_id\n",
    "        self.term_id = term_id\n",
    "        self.term_freq = term_freq\n",
    "        \n",
    "Em que o doc_id, term_id e o term_freq são inteiros.\n",
    "    \n",
    "Não foi possível calcular  as perguntas a seguir pois não tinhamos tempo o suficiente para testar o tempo de indexação do teste\n",
    "### Quanto MB de ram cada solução de índice gastou? \n",
    "\n",
    "### Em quanto tempo foi realizado a indexação? \n",
    "\n",
    "### Qual foi a média por documento?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95822f68",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
